{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4f4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# === 單個樣本的讀取與欄位補齊 ===\n",
    "def load_sample(args):\n",
    "    path, common_genes = args\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=\"\\t\", skiprows=6)\n",
    "        df.columns = [\"gene_id\", \"gene_name\", \"gene_type\", \"unstranded\", \"stranded_first\",\n",
    "                      \"stranded_second\", \"tpm_unstranded\", \"fpkm_unstranded\", \"fpkm_uq_unstranded\"]\n",
    "        df[\"gene_id\"] = df[\"gene_id\"].str.rsplit(\".\", n=1).str[0]\n",
    "        df = df.groupby(\"gene_id\").first()\n",
    "        series = df[\"tpm_unstranded\"].reindex(common_genes)\n",
    "        sample_name = os.path.basename(path).replace(\".tsv\", \"\")\n",
    "        return sample_name, series\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# === 合併 parquet 子檔案 ===\n",
    "def load_and_align(path_and_columns):\n",
    "    path, all_columns = path_and_columns\n",
    "    table = pq.read_table(path)\n",
    "    table_columns = table.column_names\n",
    "    missing_columns = [col for col in all_columns if col not in table_columns]\n",
    "    for col in missing_columns:\n",
    "        table = table.append_column(col, pa.nulls(len(table)))\n",
    "    table = table.select(all_columns)\n",
    "    return table\n",
    "\n",
    "# === 主流程函數 ===\n",
    "def preprocess(cancer_folder, input_folder, batch_size=50, n_jobs=8):\n",
    "    # Step 1: 掃描檔案路徑\n",
    "    tsv_paths = []\n",
    "    for folder in cancer_folder:\n",
    "        root_dir = os.path.join(input_folder, folder)\n",
    "        for dirpath, _, filenames in os.walk(root_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(\".tsv\"):\n",
    "                    tsv_paths.append(os.path.abspath(os.path.join(dirpath, filename)))\n",
    "    print(f\"共找到 {len(tsv_paths)} 份 TSV 檔案。\")\n",
    "\n",
    "    # Step 2: 找出共通 gene_id\n",
    "    common_genes = None\n",
    "    for path in tqdm(tsv_paths, desc=\"計算共通基因中...\"):\n",
    "        df = pd.read_csv(path, sep=\"\\t\", skiprows=6, usecols=[0], names=[\"gene_id\"], header=None)\n",
    "        genes = set(gene.rsplit('.', 1)[0] for gene in df[\"gene_id\"])\n",
    "        common_genes = genes if common_genes is None else common_genes & genes\n",
    "    common_genes = sorted(common_genes)\n",
    "\n",
    "    # Step 3: 建立輸出目錄\n",
    "    parquet_dir = os.path.join(input_folder, \"final_data\")\n",
    "    os.makedirs(parquet_dir, exist_ok=True)\n",
    "\n",
    "    # Step 4: 多核心平行讀取與批次寫入\n",
    "    tasks = [(path, common_genes) for path in tsv_paths]\n",
    "    n_jobs = n_jobs\n",
    "    \n",
    "    batch = []\n",
    "    sample_names = []\n",
    "    batch_id = 0\n",
    "\n",
    "    with Pool(processes=n_jobs) as pool:\n",
    "        for result in tqdm(pool.imap(load_sample, tasks), total=len(tasks), desc=\"處理並寫出 parquet 子檔案中...\"):\n",
    "            if result is None:\n",
    "                continue\n",
    "            sample_name, series = result\n",
    "            batch.append(series)\n",
    "            sample_names.append(sample_name)\n",
    "\n",
    "            if len(batch) == batch_size:\n",
    "                df_batch = pd.DataFrame(batch).T\n",
    "                df_batch.columns = sample_names\n",
    "                df_batch.index = common_genes\n",
    "                table = pa.Table.from_pandas(df_batch)\n",
    "                pq.write_table(table, os.path.join(parquet_dir, f\"batch_{batch_id:05}.parquet\"),\n",
    "                               compression=\"snappy\")\n",
    "                batch = []\n",
    "                sample_names = []\n",
    "                batch_id += 1\n",
    "\n",
    "    if batch:\n",
    "        df_batch = pd.DataFrame(batch).T\n",
    "        df_batch.columns = sample_names\n",
    "        df_batch.index = common_genes\n",
    "        table = pa.Table.from_pandas(df_batch)\n",
    "        pq.write_table(table, os.path.join(parquet_dir, f\"batch_{batch_id:05}.parquet\"),\n",
    "                       compression=\"snappy\")\n",
    "\n",
    "    # Step 5: 分批合併所有 parquet 子檔案為 final_data.parquet\n",
    "    print(\"分批合併 parquet 子檔案中...\")\n",
    "    paths = sorted(glob.glob(os.path.join(parquet_dir, \"*.parquet\")))\n",
    "\n",
    "    # 讀入每個 parquet 檔為 pandas DataFrame，並以 axis=1 合併（橫向）\n",
    "    df_parts = []\n",
    "    for path in tqdm(paths, desc=\"讀入 parquet 子檔\"):\n",
    "        df = pd.read_parquet(path)  # 應為 gene_id 為 index、樣本為欄位\n",
    "        df_parts.append(df)\n",
    "\n",
    "    # 最終橫向合併（以 gene 為索引）\n",
    "    final_df = pd.concat(df_parts, axis=1)\n",
    "\n",
    "    # 儲存為 Parquet\n",
    "    final_path = os.path.join(input_folder, \"final_data.parquet\")\n",
    "    final_df.to_parquet(final_path, compression=\"snappy\")\n",
    "    print(f\"✅ 最終資料完成：{final_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17170abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary module\n",
    "import os\n",
    "\n",
    "# Define the function\n",
    "def find_folder(folder):\n",
    "    \"\"\" Find folders for each cancer \"\"\"\n",
    "    # Create a empty list to store folder data\n",
    "    cancer_folder = []\n",
    "    \n",
    "    # Walk across the file and folders in \"folder\"\n",
    "    for dir in os.listdir(folder):\n",
    "        cancer_folder.append(dir)\n",
    "        \n",
    "        # Remove .txt files in this list\n",
    "        if dir.endswith(\".txt\"):\n",
    "            cancer_folder.remove(dir)\n",
    "    \n",
    "    # Return this list for further utilization\n",
    "    return cancer_folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746eb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 10759 份 TSV 檔案。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "計算共通基因中...: 100%|██████████| 10759/10759 [17:40<00:00, 10.15it/s]\n",
      "處理並寫出 parquet 子檔案中...: 100%|██████████| 10759/10759 [22:22<00:00,  8.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分批合併 parquet 子檔案中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "讀入 parquet 子檔: 100%|██████████| 216/216 [00:44<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 最終資料完成：/home/terry_0714/tcga_cancer/final_data.parquet\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/terry_0714/tcga_cancer\"\n",
    "cancer_folder = find_folder(input_folder)\n",
    "\n",
    "preprocess(cancer_folder, input_folder, batch_size=50, n_jobs=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
